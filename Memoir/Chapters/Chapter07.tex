%************************************************
\chapter{Evaluación, Comparación y Discusión de Resultados}
\label{ch:eval}
%************************************************

\section{Conjuntos de Datos}
\label{sec:datasets}

El conjunto de datos usado ha sido \emph{Spanish Universal Dependency}
\cite{udv14}, para poder ejecutar el algoritmo con estos datos, ha sido
necesario hacer una conversión de los mismos, ya que para etiquetar las frases
de \emph{test} se ha usado el \emph{\ac{POS} tagger} de Stanford, y este no
etiqueta los datos de acuerdo al
estandar\footnote{\url{http://universaldependencies.org/docs/u/pos/index.html}}. El
\emph{tagger} de Stanford utiliza las etiquetas de \textsc{AnCora
  3.0}\footnote{\url{http://clic.ub.edu/corpus/en}}. Para dicha conversión se
usó un \emph{script} en \textsc{python} proporcionado por \citeauthor{rohit2016}
\cite{rohit2016}.

En concreto, el conjunto de datos usado se llama \textsc{UD\_Spanish-AnCora},
puede descargarse a través de
\url{https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1827}. Citando
de su documentación, \textsc{AnCora} consiste en:
\begin{quotation}
  \textsc{AnCora} es un corpus del catalán \textsc{(AnCora-CA)} y del español
  \textsc{(AnCora-ES)} con diferentes niveles de anotación. El corpus de cada
  lengua contiene 500.000 palabras y están constituidos fundamentalmente por
  textos periodísticos
\end{quotation}
Como se ha mencionado en el párrafo anterior, este \emph{dataset} usa el formato
\textsc{CoNLL-U}\footnote{\url{http://universaldependencies.org/format.html}},
formato que ha sido adaptado usando el \textsc{script} mencionado anteriormente.

Como ejemplo, se proporciona el formato original de una frase en la
\autoref{lst:conllu} frente a la conversión realizada en la
\autoref{lst:converted}.
\begin{figure}[ht]
  \begin{bashcode*}{numbers=left}
Tambores        tambor  NOUN    NOUN    Gender=Masc|Number=Plur 0       root    _       _
cercanos        cercano ADJ     ADJ     Gender=Masc|Number=Plur 1       amod    _       _
,       ,       PUNCT   PUNCT   PunctType=Comm  4       punct   _       _
en      en      ADP     ADP     AdpType=Prep    1       advmod  _       MWE=en_todo_caso|MWEPOS=ADV
todo    todo    PRON    PRON    Gender=Masc|Number=Sing|PronType=Tot    4       mwe     _       _
caso    caso    NOUN    NOUN    _       4       mwe     _       _
:       :       PUNCT   PUNCT   PunctType=Colo  10      punct   _       _
todo    todo    DET     DET     Gender=Masc|Number=Sing|PronType=Ind    10      det     _       _
un      uno     DET     DET     Gender=Masc|Number=Sing|PronType=Ind    8       det     _       _
muestrario      muestrario      NOUN    NOUN    Gender=Masc|Number=Sing 1       appos   _       _
de      de      ADP     ADP     AdpType=Prep    13      case    _       _
esa     ese     DET     DET     Gender=Fem|Number=Sing|PronType=Dem     13      det     _       _
percusión       percusión       NOUN    NOUN    Gender=Fem|Number=Sing  10      nmod    _       _
urbana  urbano  ADJ     ADJ     Gender=Fem|Number=Sing  13      amod    _       _
de      de      ADP     ADP     AdpType=Prep    17      case    _       _
nuestro nuestro DET     DET     Gender=Masc|Number=Sing|Number[psor]=Plur|Person=1|Poss=Yes|PronType=Prs        17      det     _       _
tiempo  tiempo  NOUN    NOUN    Gender=Masc|Number=Sing 13      nmod    _       _
.       .       PUNCT   PUNCT   PunctType=Peri  1       punct   _       _
  \end{bashcode*}
  \caption{Frase en formato \textsc{CoNLL-U}.}
  \label{lst:conllu}
\end{figure}
\begin{figure}[ht]
  \centering
  \begin{bashcode*}{fontsize=\scriptsize,numbers=left,xleftmargin=100pt}
Tambores        NOUN    NOUN    -1
cercanos        ADJ     ADJ     0
,       PUNCT   PUNCT   3
en      ADP     ADP     0
todo    DET     PRON    3
caso    NOUN    NOUN    3
:       PUNCT   PUNCT   9
todo    DET     DET     9
un      DET     DET     7
muestrario      NOUN    NOUN    0
de      ADP     ADP     12
esa     DET     DET     12
percusión       NOUN    NOUN    9
urbana  ADJ     ADJ     12
de      ADP     ADP     16
nuestro DET     DET     16
tiempo  NOUN    NOUN    12
.       PUNCT   PUNCT   0
  \end{bashcode*}
  \caption{Frase en formato convertido.}
  \label{lst:converted}
\end{figure}

Para las pruebas realizadas, el tamaño del conjunto de datos de entrenamiento es
de 14305 frases, los datos de \emph{test} contienen 1721 sentencias.

\section{Medidas de Evaluación}
\label{sec:eval}

En orden de evaluar los resultados del algoritmo, \citeauthor{yamada2003}
proponen tres tipos de medidas. Precisión de Dependencias, Precisión en la Raíz
y clasificación Completa --- \emph{Dependency Accuracy (Dep. Acc.), Root
  Accuracy (Root Acc.)} y \emph{Complete Rate (Comp. Rate)},
respectivamente. --- Dichas mediciones se definen como
\begin{equation*}
  \begin{aligned}
    & \text{\emph{Dep. Acc}} &=& \quad\frac{\text{Número correcto de padres}}{\text{Número
        total de padres}} \\
    & \text{\emph{Root Acc}} &=& \quad\frac{\text{Número de nodos raíz correctos}}{\text{Número
        total de frases}} \\
    & \text{\emph{Comp. Rate}} &=& \quad\frac{\text{Número de frases
        parseadas por completo}}{\text{Número total de frases}} 
  \end{aligned}
\end{equation*}

\section{Comparación de Resultados}
\label{sec:results}

Tras realizar varias pruebas para ajustar parámetros, finalmente se fijó el
grado del polinómio a 2, como muestra el Código~\ref{lst:svmparams}. En cuanto a
la longitud del contexto, introducido en \autoref{subsec:featureextraction} el
mejor resultado se obtiene cuando se fija en $(2,4)$, esto es, se usa un
contexto a la izquierda de dos nodos, y un contexto a la derecha de cuatro
nodos. La \autoref{tab:results} muestra una comparación de los resultados
obtenidos con el parseador implementado frente a los resultados de
\citeauthor{rohit2016}. Se menciona aquí a \citet{rohit2016} porque implementó
el mismo algoritmo aquí expuesto, pero usando conjuntos de datos para el
Castellano. De hecho, este trabajo usa el mismo conjunto de datos que
\citeauthor{rohit2016}, \textsc{AnCora}, introducido en la
\autoref{sec:datasets}.
\begin{table}[ht]
  \myfloatalign
  \begin{tabular}{l|cc}
    \tableheadline{Kernel: $(x'\cdot x'' + 1)^2$, Contexto: $(2,4)$ }
       & \tableheadline{TFG}
       & \tableheadline{\citeauthor{rohit2016}} \\
    \toprule
    \emph{Dep. Acc.}  & 76\%   & 75\% \\
    \emph{Root Acc.}  & 67\%   & 70\% \\
    \emph{Comp. Rate} & 15\%   & 11\% \\
    \bottomrule
  \end{tabular}
  \caption{Comparación de resultados}
  \label{tab:results}
\end{table}

Como se puede apreciar, los resultados son bastante similares, llegando a
mejorar el \emph{Comp. Rate}.

Es de esperar que los resultados sean similares, ya que el algoritmo es el
mismo. Las variaciones pueden deberse al método \myTodo{Enlazar con código del
  capitulo de implementación} \textsc{extractTestFeatures}, ya que generan
salidas distintas. Es posible que esto se deba al comportamiento de los
diccionarios, ya que como bien es conocido, no tienen un orden definido. Por
tanto, al acceder a los elementos del mismo, que contienen las características
se producen pequeñas variaciones que pueden estar influyendo en el cálculo de
las características extraidas.

Otro motivo por el que pueden estar obteniéndose resultados ligeramente
distintos es el tipo de implementación para la \ac{SVM}. \citeauthor{rohit2016}
hace uso del módulo para \textsc{Python SkLearn}, este proyecto sin embargo,
utiliza la implementación original de \ac{SVM} desarrollado por
\citeauthor{libsvm}, \textsc{libsvm} \cite{libsvm}. 

%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************
